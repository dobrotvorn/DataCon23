{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMETJEDd/EsLVJiavVsFXLM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dobrotvorn/DataCon23/blob/main/Hackathon_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Описание задания\n",
        "\n",
        "\n",
        "Задание заключается в построении модели прогнозирования зоны ингибирования для антибиотиков и наночастиц серебра при взаимодействии с бактреиями.\n",
        "\n",
        "## Описание данных\n",
        "data.csv\n",
        "\n",
        "Для всех образцов в датасете использовались наночастицы серебра Ag\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   Bacteria: бактериальная клетка-мишень\n",
        "* NP_Synthesis: тип синтеза наночастиц\n",
        "* drug: название лекарства\n",
        "* drug class: класс лекарства\n",
        "* Drug dose: доза препарата\n",
        "* NP_concentration: концентрация НЧ\n",
        "* NP_size: размер НЧ\n",
        "* shape: форма НЧ\n",
        "* method: метод определения антимикробной активности\n",
        "* ZOI_drug, ZOI_NP, ZOI_drug_NP: зона ингибирования препарата, НЧ и их комбинации\n",
        "* Fold increase in antibacterial activity (%): кратное увеличение\n",
        "* антибактериальной активности (%)\n",
        "* дзета-потенциал;\n",
        "* MDR: множественная лекарственная устойчивость резистентен ли обычный препарат к целевому патогену\n",
        "\n",
        "---\n",
        "\n",
        "bacterial_descriptors.csv\n",
        "\n",
        "\n",
        "* Tax_id: id бактерии в базе данных NCBI\n",
        "* Bacteria: название бактерии\n",
        "* ingdom: царство бактерии\n",
        "* subkingdom: подцарство бактерии\n",
        "* clade: характеристика бактерии с точки зрения родственных взаимоотношений между таксономическими группами\n",
        "* phylum: филум бактерии\n",
        "* class: класс бактерии\n",
        "* order: порядок бактерии\n",
        "* family: семейство бактерии\n",
        "* genus: род бактерии\n",
        "* species: вид бактерии\n",
        "* gram: результат реакции окрашивания по Грамму для бактерии\n",
        "* min_Incub_period, avg_Incub_period, max_Incub_period h: характеристики инкубационного периода бактерии\n",
        "* growth_temp, C: температура роста бактерии\n",
        "* biosafety_level: уровень опасности бактерии\n",
        "* isolated_from: источник\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "drug_descriptors.csv\n",
        "* drug: название лекарства\n",
        "* chemID: id лекарства в базе данных CHEMBL\n",
        "* prefered_name: название лекарства\n",
        "* smiles: химическая формула лекарства"
      ],
      "metadata": {
        "id": "huku4YH5ZW1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных и библиотек"
      ],
      "metadata": {
        "id": "B0oWaT3-f9Nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Импортируем и скачиваем библиотеки"
      ],
      "metadata": {
        "id": "hchHOETkgL2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown -- quiet\n",
        "!pip install pymatgen\n",
        "!pip install rdkit\n",
        "!pip install fancyimpute --quiet\n",
        "!pip install shap\n",
        "!pip install livelossplot --quiet\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import plotly\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import plotly\n",
        "import scipy.stats as stats\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.impute import KNNImputer\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from fancyimpute import KNN\n",
        "import pymatgen.core as mg\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import rdMolDescriptors\n",
        "from rdkit.Chem.Draw import SimilarityMaps\n",
        "from zipfile import ZipFile\n",
        "\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.preprocessing import  MinMaxScaler,PolynomialFeatures,StandardScaler\n",
        "from sklearn.impute import  KNNImputer, SimpleImputer, IterativeImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import RobustScaler, KBinsDiscretizer # говорят, он хорош для выбрасов\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.model_selection import StratifiedKFold #так как у нас несбалансированные таргеты (много небольших цен и мало больших), возможно, стоит так стратифицировать.\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor, BaggingRegressor, VotingRegressor\n",
        "from sklearn.linear_model import SGDRegressor, RANSACRegressor, TheilSenRegressor, HuberRegressor, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from time import sleep\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from livelossplot import PlotLosses\n",
        "from livelossplot.outputs import MatplotlibPlot\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.impute import KNNImputer\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from fancyimpute import KNN\n",
        "from re import A\n",
        "import json\n",
        "pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "5bUc9G-mfECz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Тут захардкодим статичные переменные\n",
        "global ordinal_encoder\n",
        "global text_columns\n",
        "global path2firstDb\n",
        "global path2secondDb\n",
        "global numerics\n",
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "path2data = '/content/data.csv' if 'google.colab' in sys.modules else 'data.csv'\n",
        "path2bac_descr = '/content/bacterial_descriptors.csv' if 'google.colab' in sys.modules else 'bacterial_descriptors.csv'\n",
        "path2drug_descr = '/content/drug_descriptors.csv' if 'google.colab' in sys.modules else 'drug_descriptors.csv'"
      ],
      "metadata": {
        "id": "yeex27UlkIte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Скачиваем данные"
      ],
      "metadata": {
        "id": "ZtybgWZSkO5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url1 = 'https://raw.githubusercontent.com/dataconHack/hackathon/main/data.csv'\n",
        "url2 = 'https://raw.githubusercontent.com/dataconHack/hackathon/main/bacterial_descriptors.csv'\n",
        "url3 = 'https://raw.githubusercontent.com/dataconHack/hackathon/main/drug_descriptors.csv'\n",
        "output1 = 'data.csv'\n",
        "output2 = 'bacterial_descriptors.csv'\n",
        "output3 = 'drug_descriptors.csv'\n",
        "gdown.download(url1, output1, quiet=True)\n",
        "gdown.download(url2, output2, quiet=True)\n",
        "gdown.download(url3, output3, quiet=True)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "rHSbte-_kQiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обработка данных"
      ],
      "metadata": {
        "id": "rLHJxmsfkVo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdb = pd.read_csv(path2data)\n",
        "fdb_bak = pd.read_csv(path2bac_descr)\n",
        "fdb_drug = pd.read_csv(path2drug_descr)"
      ],
      "metadata": {
        "id": "9sr34tMCkX01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавляем дескрипторы из RDKit\n",
        "descript = ['MolLogP', 'NumValenceElectrons', 'NumHeteroatoms', 'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', 'NumRotatableBonds', 'TPSA', 'LabuteASA']\n",
        "def get_descriptors_values(desc, mol):\n",
        "    descriptors_values = []\n",
        "    for descr in descript:\n",
        "        descriptors_values.append(Descriptors.CalcMolDescriptors(mol)[descr])\n",
        "    return descriptors_values\n",
        "filled_descriptors_list = []\n",
        "for item in fdb_drug['smiles']:\n",
        "  mol = Chem.MolFromSmiles(f'{item}')\n",
        "  descriptors_with_value = get_descriptors_values(descript, mol)\n",
        "  filled_descriptors_list.append(descriptors_with_value)\n",
        "fdb_drug_desc = pd.DataFrame(filled_descriptors_list, columns=descript)\n",
        "fdb_drug = fdb_drug.join(fdb_drug_desc, how='outer')"
      ],
      "metadata": {
        "id": "TjlSefzCkmCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сольём три табличка в одну ( null не заполняли - лучше мб заполнить сразу же до мерджа)\n",
        "db =  fdb.merge(fdb_bak, how='left', left_on='Bacteria', right_on='Bacteria').merge(fdb_drug, how='left', left_on='Drug', right_on='drug').drop(['Unnamed: 0.1', 'Unnamed: 0_x', 'Unnamed: 0_y', 'Drug'], axis=1)"
      ],
      "metadata": {
        "id": "zJBUMeUokz2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Заменим остальные пропуски в данных на None, потому что сильных зависимостей не обнаружено (за исключением Surface_Charge, но там пришли к мнению, что нейтральный - это 0)\n",
        "none_mapper = { '-': np.nan, 'None': np.nan, None: np.nan, 'nan': np.nan, pd.NA : np.nan}\n",
        "db.replace(none_mapper, inplace=True)"
      ],
      "metadata": {
        "id": "gVr9__7_lO_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Преобразуем некоторые данные, заменим типы"
      ],
      "metadata": {
        "id": "L2WFVSbilrVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразует ZOI типа \"32+\", \"17+2\" в числа\n",
        "def ZOI_transform(x):\n",
        "  a = None\n",
        "  try:\n",
        "    a = eval(x)\n",
        "  except:\n",
        "    if type(x) == float or type(x) == int:\n",
        "      return a\n",
        "    a = x.split('+')[0]\n",
        "  return a\n",
        "\n",
        "# Удалим несколько строк с царством грибов\n",
        "db = db.loc[db['kingdom'] != 'Fungi']\n",
        "\n",
        "# Убирает странные концентрации НЧ\n",
        "def NP_conc_transform(x):\n",
        "  a = None\n",
        "  try:\n",
        "    a = float(x)\n",
        "  except:\n",
        "    return np.nan\n",
        "\n",
        "# Преобразуем данные ZOI и концентрации НЧ\n",
        "db['ZOI_drug'] = db['ZOI_drug'].apply(lambda x: ZOI_transform(x) if x else np.nan)\n",
        "db['ZOI_NP'] = db['ZOI_NP'].apply(lambda x: ZOI_transform(x) if x else np.nan)\n",
        "db['ZOI_drug_NP'] = db['ZOI_drug_NP'].apply(lambda x: ZOI_transform(x) if x else np.nan)\n",
        "db['NP_concentration'] = db['NP_concentration'].apply(lambda x: ZOI_transform(x) if x else np.nan)\n",
        "# Меняем тип данных на float\n",
        "db = db.astype({'ZOI_drug': np.float, 'ZOI_NP': np.float, 'ZOI_drug_NP': np.float, 'NP_concentration': np.float})"
      ],
      "metadata": {
        "id": "OuHacPdwluRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Заменим выбросы в бактериях на данные из исследований\n",
        "db_without_nulls_in_target[(db_without_nulls_in_target['Bacteria'] == 'Acinetobacter baumanii') & (db_without_nulls_in_target['ZOI_NP'] == 1000)] = 13.6\n",
        "db_without_nulls_in_target[(db_without_nulls_in_target['Bacteria'] == 'Escherichia coli') & (db_without_nulls_in_target['ZOI_NP'] == 1000)] = 11\n",
        "db_without_nulls_in_target[(db_without_nulls_in_target['Bacteria'] == 'Proteus sp.') & (db_without_nulls_in_target['ZOI_NP'] == 1000)] = 17.8\n",
        "db_without_nulls_in_target[(db_without_nulls_in_target['Bacteria'] == 'Pseudomonas aeruginosa') & (db_without_nulls_in_target['ZOI_NP'] == 1000)] = 16\n",
        "db_without_nulls_in_target[(db_without_nulls_in_target['Bacteria'] == 'Klebsiella sp') & (db_without_nulls_in_target['ZOI_NP'] == 1000)] = 17.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "vizTd8ucqZjm",
        "outputId": "f4b463d3-2769-4665-b5ba-e02d3d2dcaf6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-135e8600fc7a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bacteria'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Acinetobacter baumanii'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZOI_NP'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bacteria'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Escherichia coli'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZOI_NP'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bacteria'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Proteus sp.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZOI_NP'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bacteria'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Pseudomonas aeruginosa'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZOI_NP'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bacteria'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Klebsiella sp'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdb_without_nulls_in_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZOI_NP'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'db_without_nulls_in_target' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Проверка"
      ],
      "metadata": {
        "id": "kqbdqn-jl5qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#поиск пустых ячеек\n",
        "cols = db.columns\n",
        "# желтый - пропущенные данные, синий - не пропущенные\n",
        "colours = ['#000099', '#ffff00']\n",
        "sns.heatmap(db[cols].isnull(), cmap=sns.color_palette(colours))\n",
        "sns.set (font_scale=0.5)\n",
        "# процентный список пропущенных данных\n",
        "for col in db.columns:\n",
        "    pct_missing = np.mean(db[col].isnull())\n",
        "    print('{} - {}%'.format(col, round(pct_missing*100)))"
      ],
      "metadata": {
        "id": "U7qiq2jUlz3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Корреляционная карта\n",
        "corr = db.corr()\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "f, ax = plt.subplots(figsize=(12, 10))\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "sns.heatmap(corr, cmap=cmap, linewidths=.5, mask=mask,annot=True, fmt='.1f')"
      ],
      "metadata": {
        "id": "jhE59LfzmEYL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}